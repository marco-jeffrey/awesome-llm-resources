# Awesome LLM resources
## Contents
- [Foundations](#Foundations)
- [Fine-Tuning](#Fine-Tuning)
- [RAG](#RAG)
- [Axolotl](#Axolotl)
- [Papers](#Papers)
- [Multi-Modality](#Multi-Modality)
- [Deployment](#Deployment)
- [Papers](#Papers)
- [Miscellaneous](#Miscellaneous)


## Foundations

#### Algorithms

#### Basics

- [3Blue1Brown Whatis GPT](https://www.youtube.com/watch?v=wjZofJX0v4M)
- [fastai's legendary DL course](https://course.fast.ai/)

#### Lecture series

- [Umar's awesome DL channel](https://www.youtube.com/@umarjamilai)

#### Models

- [Llama 3 from scratch notebook](https://github.com/naklecha/llama3-from-scratch/tree/main)

## Fine-Tuning

#### Datasets

- [Hamel blog data cleaning](https://hamel.dev/notes/llm/finetuning/04_data_cleaning.html)

#### Efficient training

#### Evals

- [Hamel blog LLM evals](https://hamel.dev/blog/posts/evals/)
- [LLM eval](https://langtrace.ai/)
- [Evals blog post by Jason Way](https://www.jasonwei.net/blog/evals)

#### Guides

- [Moondream fine tune](https://github.com/vikhyat/moondream/blob/main/notebooks/Finetuning.ipynb)
- [Lora instruction fine tuning](https://github.com/wolfecameron/lora_instruction_tune)
- [Machine learning engineering for LLMs book](https://github.com/stas00/ml-engineering/)
- [When to finetune by OpenAI](https://platform.openai.com/docs/guides/fine-tuning/when-to-use-fine-tuning)
- [One year LLMs to production learnings](https://www.oreilly.com/radar/what-we-learned-from-a-year-of-building-with-llms-part-i/)

#### Monitoring

- [Observability for LLMs](https://www.honeycomb.io/llm)

#### Output structuring

- [LLM function Calling](https://github.com/imaurer/awesome-llm-json/)
- [Blog on function calling](https://fireworks.ai/blog/firefunction-v1-gpt-4-level-function-calling)
- [Hermes function calling](https://github.com/NousResearch/Hermes-Function-Calling)

#### Prompting

- [DSPY](https://github.com/stanfordnlp/dspy)
- [Prompting by Anthropic](https://docs.google.com/spreadsheets/d/19jzLgRruG9kjUQNKtCg1ZjdD6l6weA6qRXG5zLIAhC8/edit?usp=sharing)
- [Hamel blog prompting](https://hamel.dev/blog/posts/prompt/)
- [Prompt injection blog](https://simonwillison.net/series/prompt-injection/)

#### Tokenization

- [Hamel blog tokenizers](https://hamel.dev/notes/llm/finetuning/05_tokenizer_gotchas.html)

#### War stories

## RAG

#### Guides

#### Links

- [Stanford CS25- Retrieval Augmented Language Modeling](https://youtu.be/mE7IDf2SmJg?si=LKwjlYq4qiPQi3aM)


#### Projects

- [cohere RAG toolkit](https://docs.cohere.com/docs/cohere-toolkit)

## Axolotl

#### Guides

#### Projects

#### Setup

## Papers

#### Fine tuning

- [Finetuning on new knowledge](https://arxiv.org/abs/2405.05904)
- [DPO paper](https://arxiv.org/pdf/2305.18290)

#### General

#### Miscellaneous

- [Extending context length of llama-3 by 10x ](https://arxiv.org/abs/2404.19553)

#### Models

- [Vision Language models intro](https://arxiv.org/abs/2405.17247)

#### RAG

- [RAFT paper (RAG)](https://arxiv.org/abs/2403.10131)

#### Safety

- [The Instruction Hierarchy - LLM safety](https://arxiv.org/abs/2404.13208)
- [Harmlessness from AI Feedback](https://arxiv.org/abs/2212.08073)

## Multi-Modality

#### Guides

#### Projects

- [Intern-VL open source multi model GPT](https://github.com/OpenGVLab/InternVL)

## Deployment

#### APIs

#### Deployment

- [Text-Generation-Inference(TGI)](https://github.com/huggingface/text-generation-inference)

- [TensorRT-LLM/FastTransformer](https://github.com/NVIDIA/TensorRT-LLM)

- [vLLM/PageAttention/Continuous Batching](vLLM/PageAttention/Continuous Batching)

#### Guides

## Papers

#### Fine tuning

- [Finetuning on new knowledge](https://arxiv.org/abs/2405.05904)
- [DPO paper](https://arxiv.org/pdf/2305.18290)

#### General

#### Miscellaneous

- [Extending context length of llama-3 by 10x ](https://arxiv.org/abs/2404.19553)

#### Models

- [Vision Language models intro](https://arxiv.org/abs/2405.17247)

#### RAG

- [RAFT paper (RAG)](https://arxiv.org/abs/2403.10131)

#### Safety

- [The Instruction Hierarchy - LLM safety](https://arxiv.org/abs/2404.13208)
- [Harmlessness from AI Feedback](https://arxiv.org/abs/2212.08073)

## Miscellaneous

#### Links

- [Anthropic's transformer-circuits blog](https://transformer-circuits.pub/)
- [Model comparison overview](https://artificialanalysis.ai/models)
- [Hackers guide to LLM by @fastai](https://github.com/fastai/lm-hackers/blob/main/lm-hackers.ipynb)

#### Podcasts

- [Latent Space podcast with Jeremy](https://www.latent.space/p/fastai)

#### Interesting projects

- [render ui with llm](https://github.com/wandb/openui)
- [Langhain - Langsmith](https://www.langchain.com/langsmith)

